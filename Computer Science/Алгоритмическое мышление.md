# Почему твой код тормозит

## Big-O для тех, кто ещё не написал ни строчки

---

## Глава 0. Проблема масштаба

Ты написал программу. На 50 записях она работает **идеально**. На 50 000 — встаёт намертво.

Код правильный. Результат верный. Баги ни при чём.  
**Проблема — в масштабе.**

Представь ситуацию: два программиста решают одну и ту же задачу. Один получает ответ за **0.01 секунды**. Второй — за **3 часа**. Оба написали «правильный» код. Так в чём разница?

_Разница — в алгоритме._

Чтобы писать быстрый код, нужно понимать одну фундаментальную концепцию — **Big-O**.

---

## Глава 1. Что такое Big-O

### Начнём с буквы «n»

**n** — это количество входных данных. Всё просто.

- 📧 Обрабатываешь письма? **n** — это количество писем.
- 👤 Ищешь пользователя? **n** — это количество пользователей в базе.
- 🧦 Сортируешь носки? **n** — это количество носков.

Сегодня `n = 50`. Завтра `n = 50 000`. Послезавтра `n = 50 000 000`.

### Так что же такое Big-O?

> **Big-O** — это ответ на вопрос: _как изменится время работы, когда n вырастет?_

Не в секундах. Секунды зависят от процессора, языка программирования, загруженности системы. Big-O измеряет **характер роста**. Тенденцию.

**Аналогия: ты готовишь ужин.**  
Пришёл 1 гость — окей. Пришло 100 — вопрос не «сколько минут это займет», а _как изменится процесс_:

|Действие|Сложность|Почему|
|---|---|---|
|**Нарезать хлеб**|**O(1)**|Одно движение, неважно сколько гостей.|
|**Раздать тарелки**|**O(n)**|Каждому гостю по одной тарелке.|
|**Чокнуться бокалами**|**O(n²)**|Каждый должен чокнуться с каждым.|

### Почему мы пессимисты

В этой статье мы говорим «в худшем случае». Это называется **Worst Case**.

Вспомни дорогу на собеседование. Навигатор говорит «40 минут». Но бывают пробки, аварии — тогда 2 часа. Какое время ты закладываешь? Правильно, **2 часа**. Потому что опоздать страшнее, чем приехать раньше.

Big-O — это **гарантия потолка**. «Хуже точно не будет».

> **Важно:** В реальности часто опираются на _средний случай_ (Average Case). Но для старта мы фокусируемся на Worst Case — это самая надёжная база.

### Константы отбрасываются

Big-O описывает _асимптотику_ — поведение при очень больших **n**. Поэтому математическая точность уступает место общей картине:

- `O(2n)` → **O(n)** — множитель 2 не меняет характер роста (линия остаётся линией).
- `O(n + 100)` → **O(n)** — константа 100 тонет на фоне миллиона.
- `O(n² + n)` → **O(n²)** — при огромном `n²`, просто `n` уже не имеет значения.

Нас интересует **форма кривой**, а не её точные координаты.

---

## Глава 2. O(1) — Константа ⚡

_«Знаю где лежит — беру сразу»_

Представь камеру хранения на вокзале. Стена из ячеек. У каждой — номер.  
Ты подходишь с жетоном **«ячейка №247»**. Тебе не нужно открывать №1, №2, №3... Ты идёшь сразу к №247. Открываешь. Забираешь.

**Важно ли, сколько всего ячеек?** Их может быть 10 или 10 миллионов. Тебе — всё равно. Время операции одно и то же.

Вот это и есть **O(1)**. Константа.

text

```
Массив из 10 элементов:

  ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐
  │ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │ 8 │ 9 │
  └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘
                        ▲
                        │
                   arr[5] = готово!
```

text

```
Массив из 10 000 000 000 элементов:

  ┌───┬───┬───┬─── ─ ─ ─ ─ ─ ─ ───┬───┬───┐
  │ 0 │ 1 │ 2 │ ...            ... │...│ n │
  └───┴───┴───┴─── ─ ─ ─ ─ ─ ─ ───┴───┴───┘
                      ▲
              arr[7 345 812] = готово!
              Всё тот же один шаг.
```

> **Уточнение:** «Одна операция» — это абстракция. В реальности процессор может делать несколько тактов. Но количество этих действий **не зависит от размера массива** — вот что важно.
> 
> **Частая ошибка:** Думать, что O(1) значит «ровно одна секунда/операция». Нет. Это значит **фиксированное время**, не зависящее от n.

---

## Глава 3. O(n) — Линейный перебор 🚶

_«Каждого нужно проверить хотя бы раз»_

Библиотека. Тысяча книг. Нужно найти книгу, где на странице 42 написано «жираф».  
Каталога нет. Единственный способ — взять первую книгу, проверить. Не то? Вторую. Не то? Третью.

**Худший случай:** «жираф» в последней книге. Или его нет вообще.

- 10 книг → максимум 10 проверок
- 1 000 книг → максимум 1 000 проверок
- 1 000 000 книг → максимум 1 000 000 проверок

Данных в 2 раза больше — работы в 2 раза больше. **Рост пропорциональный.** Это **O(n)**.

text

```
Ищем "жираф" в массиве:

  ┌──────┬───────┬──────┬───────┬──────┬────────┐
  │ кот  │ собака│ слон │пингвин│ лиса │ жираф! │
  └──────┴───────┴──────┴───────┴──────┴────────┘
    ❌       ❌      ❌      ❌      ❌     ✅
    1        2       3       4       5      6

  Worst Case: элемент в самом конце.
```

> **На заметку:** O(n) — не «плохо». Часто это лучшее возможное решение. Чтобы прочитать все данные, нужно потратить хотя бы O(n). Линейная сложность — рабочая лошадка программирования.

---

## Глава 4. O(log n) — Деление пополам 🔍

_«Каждый шаг отбрасывает половину»_

### Игра: угадай число

Я загадал число от 1 до 100. На каждую твою попытку я говорю «больше» или «меньше».

**Стратегия: всегда бить ровно посередине.**

text

```
Диапазон: 1 ────────────────────────────── 100
                                              Осталось
Шаг 1:  "50?"   → Больше.                    вариантов
         Выбросили левую половину.               50

Шаг 2:  "75?"   → Меньше.                        25
Шаг 3:  "63?"   → Больше.                        12
Шаг 4:  "69?"   → Меньше.                         6
Шаг 5:  "66?"   → Больше.                         3
Шаг 6:  "67?"   → Больше.                         1
Шаг 7:  "68?"   → Угадал!                        ✅
```

**7 шагов. Гарантированно. Из 100 вариантов.**  
Каждый шаг отбрасывает половину мусора. Вот и весь секрет.

### Магия масштаба

|Количество вариантов (n)|Максимум шагов|
|---|---|
|100|7|
|1 000|10|
|1 000 000|20|
|1 000 000 000|30|
|**8 000 000 000**|**33**|

8 миллиардов вариантов. **Всего 33 шага.**  
Вот почему O(log n) так эффективен: данные растут в миллиарды раз, а количество операций — на единицы.

- ×2 данных → +1 шаг
- ×1000 данных → +10 шагов

### Условие: данные должны быть отсортированы

В нашей игре ответ «больше/меньше» работает только потому, что числа идут по порядку.  
**Бинарный поиск** (так это называется) требует **отсортированных данных**.

text

```
✅ Отсортированный массив — можно делить пополам:
  ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐
  │ 2 │ 5 │ 8 │12 │15 │23 │31 │42 │56 │99 │
  └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘
  Ищем 42. Середина = 15. 42 > 15 → идём в правую половину.

❌ Неотсортированный массив — деление бесполезно:
  ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐
  │56 │ 2 │99 │ 8 │42 │31 │ 5 │15 │12 │23 │
  └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘
  Без порядка нельзя понять, куда идти → только полный перебор O(n).
```

---

## Глава 5. O(n²) — Квадрат 💥

_«Каждый с каждым»_

Вспомни таблицу умножения.

- Таблица 3×3: `3 × 3 = 9` операций.
- Таблица 10×10: `10 × 10 = 100` операций.

А теперь смотри, что происходит при реальном росте **n**:

|n|n² (операций)|Ощущение в реальности|
|---|---|---|
|100|10 000|Мгновенно|
|1 000|1 000 000|Быстро|
|10 000|100 000 000|Заметная пауза|
|**100 000**|**10 000 000 000**|**Можно идти пить кофе (долго)**|

**Увеличили n в 10 раз — операций стало в 100 раз больше.**

### Как это выглядит в коде

O(n²) — это почти всегда **цикл внутри цикла** по одним и тем же данным:

Python

```
для каждого элемента A:           ← n раз
    для каждого элемента B:       ← n раз
        сравнить A и B
# Итого: n × n = n²
```

### Ловушка: на маленьких данных O(n²) незаметен

- При `n = 100` разница между O(n) и O(n²) не видна глазу.
- При `n = 100 000`:
    - O(n) → доли секунды.
    - O(n²) → минуты.
    - Теперь разница видна. **Но код уже в продакшене.**

**Когда O(n²) допустим?**

- 🟢 **n < 100** — не парься.
- 🟡 **n < 1000** — скорее всего, нормально.
- 🔴 **n > 10 000** — срочно ищи другой алгоритм.

---

## Глава 6. O(n log n) — Золотая середина

Между O(n) и O(n²) есть важный класс: **O(n log n)**.  
Это сложность большинства эффективных алгоритмов сортировки (QuickSort, MergeSort). Быстрее, чем квадрат, но медленнее, чем линия.

|n|O(n)|O(n log n)|O(n²)|
|---|---|---|---|
|1 000|1 тыс.|10 тыс.|1 млн|
|10 000|10 тыс.|140 тыс.|100 млн|
|100 000|100 тыс.|1.7 млн|**10 млрд**|

### «График боли»

text

```
  Операции
    ▲
    │                                           
    │                                        ⟋ O(n²) 💀
    │                                      ⟋   УЖАСНО
    │                                   ⟋
    │                                ⟋
    │                             ⟋
    │                          ⟋
    │                       ⟋
    │                    ⟋          ⟋ O(n log n) 😬
    │                 ⟋          ⟋    ПЛОХО
    │              ⟋          ⟋
    │           ⟋         ⟋
    │        ⟋        ⟋
    │      ⟋      ⟋         ╱ O(n) 😐
    │    ⟋    ⟋          ╱    НОРМАЛЬНО
    │  ⟋  ⟋          ╱
    │⟋⟋          ╱
    │╱       ╱
    │    ╱   ╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌ O(log n) 😎
    │ ╱                                  ОТЛИЧНО
    │╱
    ├─────────────────────────────────────────── O(1) ⚡
    │                                            ИДЕАЛ
    └────┬────────┬─────────┬─────────┬───────▶
        10      100     1 000    10 000      n
```

---

## Таблица-шпаргалка

|Сложность|Название|Пример|Оценка|
|---|---|---|---|
|**O(1)**|Константная|Доступ по индексу массива|🟢 Идеал|
|**O(log n)**|Логарифмическая|Бинарный поиск|🟢 Супер|
|**O(n)**|Линейная|Проход циклом|🟡 Норм|
|**O(n log n)**|Линейно-логарифмическая|Эффективная сортировка|🟡 Приемлемо|
|**O(n²)**|Квадратичная|Вложенный цикл|🔴 Опасно|

---

## Глава 7. Space Complexity — Память тоже ресурс

Big-O работает и для памяти: не «сколько байт займет», а «как растёт потребление RAM при росте n».

**Пример: поиск дубликатов в списке**

1. **Решение А:** Сравнить каждый элемент с каждым (вложенные циклы).
    
    - ⏳ Время: **O(n²)**
    - 💾 Память: **O(1)** — мы не создаем новые структуры, работаем внутри имеющейся.
2. **Решение Б:** Запоминать уже встреченные элементы в отдельный набор (HashSet).
    
    - ⏳ Время: **O(n)** — всего один проход.
    - 💾 Память: **O(n)** — в худшем случае храним копию всех элементов.

||Время|Память|
|---|---|---|
|**Решение А**|O(n²) 😰|O(1) 😊|
|**Решение Б**|O(n) 😊|O(n) 😐|

**Trade-off (компромисс):** В программировании мы часто «покупаем» скорость ценой памяти, и наоборот.

---

## Глава 8. Практика 🏋️‍♂️

Попробуй решить сам, прежде чем открывать ответ.

### Задача 1: Охранник на входе

В клуб заходят люди. У охранника — список из 100 VIP-имён. Каждого гостя он ищет в списке, проводя пальцем сверху вниз. Пришло 500 человек. Какая сложность для всей толпы?

<details> <summary><b>👀 Показать ответ</b></summary>

**Ответ:** O(n × m) или O(n), зависит от того, что считать переменной.

Для каждого из 500 гостей (n) — до 100 проверок (m).

- Если список фиксирован (всегда 100 имён): **O(n)** — линейная от кол-ва гостей.
- Если и список, и гости растут: **O(n × m)**.

_Как ускорить?_ Отсортировать список VIP → бинарный поиск → O(n log m).

</details>

### Задача 2: Плейлист

А) Плейлист из 10 000 песен перемешан случайно. Ищем песню "Yesterday".  
Б) Тот же плейлист, но отсортирован по алфавиту.

<details> <summary><b>👀 Показать ответ</b></summary>

**А) O(n)** — перебираем с начала. До 10 000 шагов.  
**Б) O(log n)** — бинарный поиск. До 14 шагов.

Разница в скорости: ~700 раз.

</details>

### Задача 3: Конфликты на свадьбе

200 гостей. Нужно проверить каждую пару на возможный конфликт (дрались ли они раньше). Сколько пар нужно проверить?

<details> <summary><b>👀 Показать ответ</b></summary>

Формула: `n × (n-1) / 2`.  
Это **O(n²)**.

Для 200 гостей — 19 900 пар.  
При 10 000 гостей — 50 миллионов пар. Компьютер справится, но на пределе.

</details>

### Задача 4: Телефонная книга (Блиц)

У тебя 1 000 000 контактов.

1. Книга **не** отсортирована. Ищем "Ивана Петрова".
2. Книга **отсортирована**. Ищем "Ивана Петрова".
3. Ты знаешь **позицию** (индекс 547832).

<details> <summary><b>👀 Показать ответ</b></summary>

|Вариант|Сложность|Шагов (худший случай)|
|---|---|---|
|Не отсортирована|**O(n)**|1 000 000|
|Отсортирована|**O(log n)**|~20|
|По индексу|**O(1)**|1|

</details>

---

## Глава 9. Итого

### Главная таблица понимания

|Big-O|Механика|Мнемоника|
|---|---|---|
|**O(1)**|Не зависит от n|"Знаю номер — беру"|
|**O(log n)**|Деление пополам|"Телефонная книга"|
|**O(n)**|Пропорционально|"Каждого проверить"|
|**O(n log n)**|Чуть хуже линии|"Сортировка"|
|**O(n²)**|Каждый с каждым|"Вложенный цикл"|

### Чеклист здорового кода

- ✅ **n** — это количество входных данных.
- ✅ **Big-O** — это характер роста, а не секунды.
- ✅ **Worst Case** — рассчитываем на худшее.
- ✅ **Константы** — отбрасываются (2n = n).
- ✅ **Время и память** — это весы. Часто жертвуем одним ради другого.

### Главный вывод (запомни это)

- Видишь **один цикл** — думаешь **O(n)**.
- Видишь **вложенный цикл** — думаешь **O(n²)**.
- Видишь **деление пополам** — думаешь **O(log n)**.
- Видишь **доступ по индексу** — думаешь **O(1)**.

Это станет автоматизмом. Нужна только практика. Удачи в коде! 🚀