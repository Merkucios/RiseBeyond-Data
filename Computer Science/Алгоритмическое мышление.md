# Почему твой код тормозит

## Big-O для тех, кто ещё не написал ни строчки кода

---

### Глава 0. Проблема масштаба

Ты написал программу. На 50 записях она работает идеально. На 50 000 — встаёт намертво.

Код правильный. Результат верный. Баги ни при чём. **Проблема — в масштабе.**

Два программиста решают одну задачу. Один получает ответ за `0.01` секунды. Второй — за `3` часа. Оба написали «рабочий» код. Разница — в **алгоритме**.

Чтобы писать быстрый код, нужно понять одну концепцию — **Big-O**.

---

### Глава 1. Что такое Big-O

#### Начнём с буквы «n»

**n** — это количество входных данных. Всё просто:

- Обрабатываешь письма? **n** — количество писем.
- Ищешь пользователя? **n** — количество пользователей в базе.
- Сортируешь носки? **n** — количество носков.

Сегодня `n = 50`. Завтра `n = 50 000`. Послезавтра `n = 50 000 000`.

#### Так что же такое Big-O?

> Big-O — это ответ на вопрос: **как изменится время работы, когда n вырастет?**

Мы не измеряем в секундах. Секунды зависят от процессора, языка и погоды. Big-O измеряет **характер роста**. Тенденцию.

**Аналогия:** Ты готовишь ужин. Пришёл 1 гость — окей. Пришло 100 — вопрос не «сколько минут», а как изменится процесс:

- 🍞 **Нарезать хлеб:** одно движение, неважно сколько гостей → **O(1)**
- 🍽️ **Раздать тарелки:** каждому по одной → **O(n)**
- 🥂 **Все чокнулись бокалами со всеми:** каждый с каждым → **O(n²)**

#### Почему мы пессимисты?

В этой статье мы говорим «в худшем случае». Это называется **Worst Case**.

Представь: дорога на собеседование. Навигатор говорит «40 минут». Но бывают пробки — тогда 2 часа. Какое время закладываешь? **2 часа**. Потому что опоздать страшнее, чем приехать раньше.

Big-O — это гарантия потолка. **«Хуже точно не будет».**

> **Важно:** В реальности часто опираются на средний случай (_Average Case_). Многие алгоритмы имеют плохой _Worst Case_, но отличный _Average_. Для старта мы фокусируемся на _Worst Case_ — это надёжная база.

#### Константы отбрасываются

Big-O описывает асимптотику — поведение при очень больших `n`. Поэтому:

- `O(2n) = O(n)` — множитель 2 не меняет характер роста.
- `O(n + 100) = O(n)` — константа 100 тонет в данных.
- `O(n² + n) = O(n²)` — младший член `n` несущественен, когда `n²` огромен.

Нас интересует **форма кривой**, а не её точное положение.

---

### Глава 2. O(1) — Константа ⚡

> _«Знаю где лежит — беру сразу»_

Представь камеру хранения на вокзале. Стена из ячеек. У каждой — номер.  
Ты подходишь с жетоном «ячейка №247». Не нужно открывать №1, №2, №3... Идёшь сразу к №247. Открываешь. Забираешь.

Важно ли, сколько всего ячеек? Их может быть 10 или 10 миллионов. **Тебе — всё равно.** Время одно и то же. Вот это и есть **O(1)**.

**Массив из 10 элементов:**

<pre> ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐ │ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │ 8 │ 9 │ └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘ ▲ │ arr[5] = готово! </pre>

**Массив из 10 000 000 000 элементов:**

<pre> ┌───┬───┬───┬─── ─ ─ ─ ─ ─ ─ ───┬───┬───┐ │ 0 │ 1 │ 2 │ ... ... │...│ n │ └───┴───┴───┴─── ─ ─ ─ ─ ─ ─ ───┴───┴───┘ ▲ arr[7 345 812] = готово! Всё тот же один шаг. </pre>

> **Частая ошибка:** Думать, что O(1) значит «ровно одна операция». Нет. Это значит **фиксированное количество** операций, не зависящее от `n`. Может быть 1, может быть 50 — главное, что это число не растёт.

---

### Глава 3. O(n) — Линейный перебор 🚶

> _«Каждого нужно проверить хотя бы раз»_

Библиотека. Тысяча книг. Нужно найти книгу, где на странице 42 написано «жираф».  
Каталога нет. Единственный способ — взять первую книгу, проверить. Не то? Вторую. Не то? Третью.

**Худший случай:** «Жираф» в последней книге. Или его нет вообще.

<pre> 10 книг → максимум 10 проверок 1 000 книг → максимум 1 000 проверок 1 000 000 книг → максимум 1 000 000 проверок </pre>

Данных в 2 раза больше — работы в 2 раза больше. Рост пропорциональный. Это **O(n)**.

<pre> Ищем "жираф" в массиве: ┌──────┬───────┬──────┬───────┬──────┬────────┐ │ кот │ собака│ слон │пингвин│ лиса │ жираф! │ └──────┴───────┴──────┴───────┴──────┴────────┘ ❌ ❌ ❌ ❌ ❌ ✅ 1 2 3 4 5 6 Worst Case: элемент в самом конце. </pre>

> **Важно:** O(n) — не «плохо». Часто это лучшее возможное решение. Чтобы прочитать все данные, нужно хотя бы O(n). Линейная сложность — рабочая лошадка программирования.

---

### Глава 4. O(log n) — Деление пополам 🔍

> _«Каждый шаг отбрасывает половину»_

#### Игра: Угадай число

Я загадал число от 1 до 100. На каждую попытку говорю «больше» или «меньше».  
Стратегия: всегда бить посередине.

<pre> Диапазон: 1 ────────────────────────────── 100 Осталось Шаг 1: "50?" → Больше. вариантов Выбросили половину. 50 Шаг 2: "75?" → Меньше. 25 Шаг 3: "63?" → Больше. 12 Шаг 4: "69?" → Меньше. 6 Шаг 5: "66?" → Больше. 3 Шаг 6: "67?" → Больше. 1 Шаг 7: "68?" → Угадал! ✅ </pre>

**7 шагов. Гарантированно. Из 100 вариантов.**  
Каждый шаг отбрасывает половину. Вот и весь секрет.

#### Масштаб

|Количество вариантов (n)|Максимум шагов|
|---|---|
|100|7|
|1 000|10|
|1 000 000|20|
|1 000 000 000|30|
|8 000 000 000|33|

**8 миллиардов вариантов. 33 шага.**  
Вот почему O(log n) так эффективен: данные растут в миллиарды раз, а шаги — на единицы.

- ×2 данных → **+1 шаг**
- ×1000 данных → **+10 шагов**

#### Условие: Данные должны быть отсортированы

В нашей игре ответ «больше/меньше» работает, потому что числа упорядочены.  
**Бинарный поиск** (так называется эта стратегия) требует отсортированных данных.

<pre> Отсортированный массив — можно делить пополам: ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐ │ 2 │ 5 │ 8 │12 │15 │23 │31 │42 │56 │99 │ └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘ Ищем 42. Середина = 15. 42 > 15 → правая половина. Нашли за 2-3 шага. </pre>

> **Цена:** Сортировка стоит минимум `O(n log n)`. Но если искать будешь много раз — окупается сполна.

---

### Глава 5. O(n²) — Квадрат 💥

> _«Каждый с каждым»_

#### Таблица умножения

- Таблица 3×3: `3 × 3 = 9` операций
- Таблица 10×10: `10 × 10 = 100` операций

А теперь смотри, что происходит при росте `n`:

|n|n² (операций)|Реальность|
|---|---|---|
|100|10 000|Мгновенно|
|1 000|1 000 000|Быстро|
|10 000|100 000 000|Заметная пауза|
|100 000|10 000 000 000|Минуты ожидания|

Увеличили `n` в 10 раз — операций стало в **100 раз больше**.

#### Как это выглядит в коде

O(n²) — почти всегда **цикл внутри цикла** по одним и тем же данным:

Python

```
для каждого элемента A:           # n раз
    для каждого элемента B:       # n раз
        сравнить A и B
```

Итого: `n × n = n²`

#### Ловушка: На маленьких данных O(n²) незаметен

<pre> n = 100: O(n) → 100 операций O(n²) → 10 000 операций Обе — мгновенно. Проблема не видна. n = 100 000: O(n) → 100 000 операций ← доли секунды O(n²) → 10 000 000 000 операций ← минуты/часы Теперь видно. Но код уже в проде. </pre>

#### Когда O(n²) допустим?

- `n < 100` — не парься.
- `n < 1000` — скорее всего, нормально.
- `n > 10 000` — срочно ищи другой алгоритм.

---

### Глава 6. O(n log n) — Золотая середина ⚖️

Между `O(n)` и `O(n²)` есть важный класс: **O(n log n)**.  
Это сложность большинства эффективных алгоритмов сортировки (QuickSort, MergeSort). Быстрее, чем квадрат, но медленнее, чем линия.

|n|O(n)|O(n log n)|O(n²)|
|---|---|---|---|
|1 000|1 000|10 000|1 000 000|
|10 000|10 000|140 000|100 000 000|
|100 000|100 000|1 700 000|10 000 000 000|

O(n log n) растёт существенно медленнее O(n²), но всё же быстрее чистой линии O(n).

#### «График боли»

<pre> Операции ▲ │ │ ⟋ O(n²) │ ⟋ УЖАСНО │ ⟋ │ ⟋ │ ⟋ │ ⟋ │ ⟋ │ ⟋ ⟋ O(n log n) │ ⟋ ⟋ ПЛОХО │ ⟋ ⟋ │ ⟋ ⟋ │ ⟋ ⟋ │ ⟋ ⟋ ╱ O(n) │ ⟋ ⟋ ╱ НОРМАЛЬНО │ ⟋ ⟋ ╱ │⟋⟋ ╱ │╱ ╱ │ ╱ ╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌╌ O(log n) │ ╱ ОТЛИЧНО │╱ ├─────────────────────────────────────────── O(1) │ ОТЛИЧНО └────┬────────┬─────────┬─────────┬───────▶ 10 100 1 000 10 000 n </pre>

#### Таблица-шпаргалка

|Сложность|Название|Пример|Оценка|
|---|---|---|---|
|**O(1)**|Константная|Доступ по индексу|🟢 Идеал|
|**O(log n)**|Логарифмическая|Бинарный поиск|🟢 Супер|
|**O(n)**|Линейная|Проход циклом|🟡 Норм|
|**O(n log n)**|Линейно-логарифмическая|Эффективная сортировка|🟡 Приемлемо|
|**O(n²)**|Квадратичная|Вложенный цикл|🔴 Опасно|

---

### Глава 7. Space Complexity — Память тоже ресурс 🧠

Big-O работает и для памяти: не «сколько байт», а **«как растёт потребление при росте n»**.

#### Пример: Поиск дубликатов в списке

**Решение А: Сравнить каждый с каждым**

- Время: `O(n²)`
- Память: `O(1)` — ничего дополнительного не храним.

**Решение Б: Запоминать встреченные элементы (HashSet)**

- Время: `O(n)` — один проход.
- Память: `O(n)` — храним до `n` элементов.

||Время|Память|
|---|---|---|
|**Решение А**|O(n²) 😰|O(1) 😊|
|**Решение Б**|O(n) 😊|O(n) 😐|

> **Trade-off:** Часто можно «купить» скорость за память и наоборот.

---

### Глава 8. Практика 🏋️

#### Задача 1: Охранник на входе

**Ситуация:** В клуб заходят люди. У охранника — список из 100 VIP-имён. Каждого гостя он ищет в списке, проводя пальцем сверху вниз. Пришло 500 человек.

**Ответ:**  
Для каждого из 500 гостей — до 100 проверок.

- Если список фиксирован (100 имён всегда): `O(n)` от количества гостей.
- Если и список, и гости растут: `O(n × m)`.

**Как ускорить?** Отсортировать список по алфавиту → бинарный поиск → `O(log m)` на гостя.

#### Задача 2: Плейлист

**А)** Плейлист из 10 000 песен, перемешан случайно. Ищем конкретную песню.  
**Б)** Тот же плейлист, отсортирован по алфавиту.

**Ответ:**

- А) `O(n)` — перебираем с начала.
- Б) `O(log n)` — бинарный поиск.

<pre> Ситуация А: до 10 000 шагов Ситуация Б: до 14 шагов Разница: ~700 раз. </pre>

#### Задача 3: Проверка конфликтов на свадьбе

**Ситуация:** 200 гостей. Нужно проверить каждую пару на конфликт.

**Ответ:**  
`n × (n-1) / 2` = 19 900 пар. **O(n²)**.  
При `n = 10 000` гостей: ~50 000 000 пар. Компьютер справится за секунды, но при `n = 1 000 000` уже начнутся проблемы.

#### Задание 0.7: Поиск в телефонной книге

**Условие:** У тебя телефонная книга с 1 000 000 контактов.

- **a)** Книга не отсортирована. Найди номер Ивана Петрова.
- **b)** Книга отсортирована по алфавиту. Найди номер Ивана Петрова.
- **c)** Ты знаешь позицию (индекс 547832). Получи контакт.

|Вариант|Сложность|Шагов (худший случай)|Объяснение|
|---|---|---|---|
|**a)** Не отсортирована|`O(n)`|до 1 000 000|Перебираем с начала до конца|
|**b)** Отсортирована|`O(log n)`|до 20|Бинарный поиск: каждый шаг делит пополам|
|**c)** По индексу|`O(1)`|1|Прямой доступ, размер книги не важен|

---

### Глава 9. Итого 🏁

#### Главная таблица

|Big-O|Что происходит|Запоминалка|
|---|---|---|
|**O(1)**|Не зависит от n|"Знаю номер — беру"|
|**O(log n)**|Каждый шаг: ÷2 данных|"Делю пополам"|
|**O(n)**|Пропорционально|"Каждого проверить"|
|**O(n log n)**|Между линией и квадратом|"Сортировка"|
|**O(n²)**|Каждый с каждым|"Цикл в цикле"|

#### Чеклист

- ✅ **n** — количество входных данных.
- ✅ **Big-O** — характер роста, не секунды.
- ✅ **Worst Case** — гарантия потолка (но _Average Case_ тоже важен).
- ✅ **Константы отбрасываются** — `O(2n) = O(n)`.
- ✅ **O(1) ≠ «одна операция»** — фиксированное количество, не зависит от `n`.
- ✅ **O(n)** — часто лучшее возможное.
- ✅ **O(log n)** — требует отсортированных данных.
- ✅ **O(n²)** — окей для малых `n`, опасно для больших.
- ✅ **Время и память** — два ресурса, trade-off.

#### Главный вывод

> Видишь один цикл — думаешь **O(n)**.  
> Видишь вложенный цикл — думаешь **O(n²)**.  
> Видишь деление пополам — думаешь **O(log n)**.  
> Видишь доступ по индексу — думаешь **O(1)**.

Это станет автоматизмом. Нужна только практика.